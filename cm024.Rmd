---
title: "CONJ620: CM 2.4"
subtitle: "Multiple linear regression"
author: "Alison Hill, Chester Ismay, Albert Y. Kim"
date: "7/26/2018"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


# Logistics

- A complete knitted `html` file is due on Sakai by beginning of class Tuesday July 31th (2:30pm). 
- This lab is structured to be similar to this [Case Study on Seattle House Prices from ModernDive](http://moderndive.netlify.com/12-thinking-with-data.html#seattle-house-prices). Please open it and follow along with both datasets!

# Overview

We'll work with data from this [538 article](https://fivethirtyeight.com/features/higher-rates-of-hate-crimes-are-tied-to-income-inequality/). From the article:

We collected data on key socioeconomic factors for each state, including indicators for:

- education (percent of adults 25 and older with at least a high school degree, as of 2009), 
- diversity
    - percent nonwhite population, 2015
    - percent noncitizen population, 2015,
- geographic heterogeneity (percent population in metropolitan areas, 2015), 
- economic health 
    - median household income, 
    - 2016 seasonally adjusted unemployment (September 2016), 
    - percent poverty among white people. 2015, and 
    - income inequality as measured by the Gini index, 2015)
- percent of the population voted for Donald Trump. 

In this lab, we'll use a subset of these variables to predict hate crimes in the US.

# The Data

This data is included in the `fivethirtyeight` package in the [`hate_crimes` data frame](https://fivethirtyeight-r.netlify.com/reference/hate_crimes.html), which we’ll refer to as the “Hate crimes” dataset. You can use [`?hate_crimes`](https://fivethirtyeight-r.netlify.com/reference/hate_crimes.html) to read more about it and the variables.

You'll need to load these packages to do this lab:

```{r load_packages, include = TRUE}
library(fivethirtyeight)
library(skimr)
library(tidyverse)
library(GGally) # new to you!
```


# Alison editorializing here...

There are two possible outcome variables here: 

1. pre-election data from the FBI and 
2. post-election data from the SPLC

- The outcome variable, $y$, the average annual hate crimes per 100,000 population, FBI, 2010-2015 (`avg_hatecrimes_per_100k_fbi`)
- The outcome variable, $y$, hate crimes per 100,000 population, Southern Poverty Law Center, Nov. 9-18, 2016 (`hate_crimes_per_100k_splc`)

Proposal: focus on building pre-election model, then perhaps compare coefficients to post-election model on their own?

# All together

We'll still use `hate_crimes` to demonstrate multiple regression with:

1. A numerical outcome variable $y$, in this case the average annual hate crimes per 100,000 population according to the FBI for years 2010-2015 (`avg_hatecrimes_per_100k_fbi`)
1. Two explanatory variables:
    1. A first numerical explanatory variable $x_1$. In this case, each state's percent noncitizen population in 2015 (`share_non_citizen`)
    1. A second numerical explanatory variable $x_2$. In this case, each state's percent population in metropolitan areas in 2015 (`share_pop_metro`) 

In the lab, we'll consider a different scenario:

1. The same numerical outcome variable $y$: credit card balance.
1. Two new explanatory variables:
    1. A first numerical explanatory variable $x_1$: their credit rating.
    1. A second numerical explanatory variable $x_2$: their age.

# EDA

Recall that a [new exploratory data analysis](http://moderndive.netlify.com/6-regression.html#model1EDA) involves three things:

* Looking at the raw values.
* Computing summary statistics of the variables of interest.
* Creating informative visualizations.

General functions you'll want to call- add narrative to interpret each!:

- `dplyr::glimpse()`
- `skimr::skim()`
- `ggplot2::ggplot()`
    - `geom_histogram()` or `geom_density()` for numeric continuous variables
    - `geom_bar()` or `geom_col()` for categorical variables

At this stage, you may also find your want to use `filter`, `mutate`, `arrange`, `select`, or `count`. Let your questions lead you!


## Look at the raw values

- How many states are here? Are they all "states"?

```{r}
glimpse(hate_crimes)
```

- Let's merge in `region` to, using the built-in `states` dataset in R:

```{r}
# load the data
data("state")

# make a dataframe
state_info <- data_frame(state_name = state.name, 
                         state_region = state.region)

# drop DC, merge to get region
hate_states <- hate_crimes %>% 
  filter(!state == "District of Columbia") %>% 
  left_join(state_info, by = c("state" = "state_name"))
```

- Let's select just the variables we need

```{r}
hate_demo <- hate_states %>% 
  select(avg_hatecrimes_per_100k_fbi, share_pop_metro, share_non_citizen)
```

## Compute summary statistics

```{r}
skim(hate_demo)
```

For simple regression, we also calculated correlation coefficients. For [multiple regression](http://moderndive.netlify.com/7-multiple-regression.html#model3EDA), your EDA can be more efficient by computing multiple correlation coefficients at once. We'll use the `cor()` function to do this.

```{r}
cor(hate_demo)
```

Wah- those are all `NA`!

```{r}
cor(hate_demo, use = "pairwise.complete.obs")
```


You could do the same thing in the `corrr` package, using the `correlate` function:

```{r}
library(corrr)
correlate(hate_demo)
```

Your interpretation of these correlation coefficents goes here:

1.
1.
1.


## Create informative visualizations

```{r}
# Histogram of share_pop_metro:
ggplot(hate_demo, aes(x = share_pop_metro)) +
  geom_density() +
  labs(x = "metro population percent", title = "Geographic heterogeneity")

# Histogram of share_non_citizen:
ggplot(hate_demo, aes(x = share_non_citizen)) +
  geom_density() +
  labs(x = "", title = "Diversity")
```

Luckily, we just have two predictors here. We could actually make all the plots using `GGally::ggpairs()`.

```{r}
ggpairs(hate_demo)
```

You get: 

- The correlation coefficients, AND
- The univariate density plots, AND
- The bivariate scatterplots!

In the article, they claim that two variables remained significant in both model outputs: income inequality and percent population with a high school degree. The three explanatory/predictor variables we’ll use are:

- `gini_index` (income inequality)
- `share_pop_hs` 
- `share_vote_trump` (make categorical?)


# Bivariate EDA

Let's look at all 3 of these predictors of the pre-election hate crimes:

```{r}
hate_crimes %>% 
  select(avg_hatecrimes_per_100k_fbi,
         gini_index, share_pop_hs, share_vote_trump) %>%
  ggpairs(.)
```

OK, one point appears to be an outlier. I'm going to color by DC so you can see this:

```{r}
hate_crimes %>% 
  mutate(dc = ifelse(state == "District of Columbia", "dc", "not")) %>% 
  select(avg_hatecrimes_per_100k_fbi, dc,
         gini_index, share_pop_hs, share_vote_trump) %>%
  ggpairs(., mapping = aes(color = dc))
```

This is where Alison goes off track to figure this out...

```{r}
hate_crimes %>% 
  filter(!state == "District of Columbia") %>% 
  select(avg_hatecrimes_per_100k_fbi, 
         gini_index, share_pop_hs, share_vote_trump, share_non_citizen) %>%
  ggpairs(.)
```

Question: should we exclude District of Columbia here? I think so- it appears to have multivariate weirdness.

```{r}
hate_crimes %>% 
  filter(state == "District of Columbia")
```


Here is me excluding it (and making categorical versions at the same time:


```{r}
hate_states <- hate_crimes %>% 
  filter(!state == "District of Columbia") %>%
  mutate(
    cat_pop_hs = case_when(
      share_pop_hs < .85 ~ 0, #low
      between(share_pop_hs, .85, .89) ~ 1, #medium
      TRUE ~ 2 #high
      ),
    cat_non_citizen = case_when(
      share_non_citizen <= .05 ~ 0, #low
      TRUE ~ 1 #high
      ),
    cat_trump = case_when(
      share_vote_trump < .5 ~ "low",
      TRUE ~ "high"
    ))
```


# Multiple regression models

Group 1: Two numerical predictors

```{r}
hate_model1 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   share_pop_hs,
                 data = hate_states)

summary(hate_model1)
```

Then maybe group 2:

```{r}
hate_model2 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   share_pop_hs +
                   share_vote_trump,
                 data = hate_states)

summary(hate_model2)
```

Then maybe group 3:

```{r}
hate_model3 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   share_pop_hs +
                   cat_trump,
                 data = hate_states)

summary(hate_model3)
```

Then maybe group 4 (tricky! need to talk about factors :):

```{r}
hate_model4 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   as.factor(cat_pop_hs),
                 data = hate_states)

summary(hate_model4)
```


hail mary here
```{r}
library(janitor)
thai_d <- readxl::read_xlsx(here::here("data", "Thai_vitamin D dataset.xlsx"),
                            sheet = 1) %>% 
  clean_names()

glimpse(thai_d)

ggplot(thai_d, aes(x = ageyears, y = x25d, color = sex)) +
  geom_point() +
  facet_wrap(~sex) +
  geom_smooth(method = "lm")

mod <- lm(x25d ~ ageyears + sex, data = thai_d)
mod2 <- lm(x25d ~ ageyears*sex, data = thai_d)
```



